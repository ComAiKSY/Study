# TensorFlow ì„í¬íŠ¸ (ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ì˜ í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬)
import tensorflow as tf

# Intel MKL ê´€ë ¨ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•œ í™˜ê²½ ì„¤ì • (ìœˆë„ìš°ì—ì„œ ì˜¤ë¥˜ ë°©ì§€ìš©)
import os
os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# ========================================================
# ğŸ§  AutoEncoder í´ë˜ìŠ¤ ì •ì˜
# - ì…ë ¥ ë°ì´í„°ë¥¼ ì••ì¶•(Encode)í–ˆë‹¤ê°€ ë‹¤ì‹œ ë³µì›(Decode)í•˜ëŠ” ì‹ ê²½ë§ êµ¬ì¡°
# - íŠ¹ì§• í•™ìŠµ, ë…¸ì´ì¦ˆ ì œê±°, ì°¨ì› ì¶•ì†Œ ë“± ë‹¤ì–‘í•œ ìš©ë„ë¡œ ì‚¬ìš©ë¨
# ========================================================
class AutoEncoder:
    def __init__(self):
        # ëª¨ë¸ êµ¬ì„± ìš”ì†Œ ì´ˆê¸°í™” (ë‚˜ì¤‘ì— build_model()ì—ì„œ ì±„ì›Œì§)
        self.encoder = None          # ì…ë ¥ â†’ ì ì¬ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë¸
        self.decoder = None          # ì ì¬ë²¡í„° â†’ ë³µì›ëœ ì¶œë ¥ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ëª¨ë¸
        self.en_decoder = None       # encoder + decoder ì „ì²´ AutoEncoder

        # ìì£¼ ì“°ëŠ” í™œì„±í™” í•¨ìˆ˜ ì €ì¥
        self.relu = tf.keras.activations.relu   # ì€ë‹‰ì¸µì— ë§ì´ ì‚¬ìš©ë¨ (ì–‘ìˆ˜ë§Œ í™œì„±í™”)
        self.tanh = tf.keras.activations.tanh   # ì ì¬ê³µê°„ì— ë§ì´ ì‚¬ìš©ë¨ ([-1, 1] ë²”ìœ„)

        # ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° (MNIST ê¸°ì¤€ 28x28 = 784ì°¨ì› ë²¡í„°)
        self.input_output_dim = 784

        # ì€ë‹‰ì¸µ ë…¸ë“œ ìˆ˜ ì„¤ì • (ììœ ë¡­ê²Œ ë°”ê¿€ ìˆ˜ ìˆìŒ)
        self.encoder_hidden_layers = [200, 200]  # ì¸ì½”ë” íˆë“ ë ˆì´ì–´ êµ¬ì„±
        self.decoder_hidden_layers = [200, 200]  # ë””ì½”ë” íˆë“ ë ˆì´ì–´ êµ¬ì„±

        # ì ì¬ê³µê°„(latent space) ì°¨ì› ìˆ˜ â†’ ì´ê±¸ ì••ì¶•ëœ ë²¡í„°ë¡œ ì‚¬ìš©
        self.code_dim = 32

    # ===================================================
    # ğŸ“¦ ëª¨ë¸ êµ¬ì„± í•¨ìˆ˜: ì¸ì½”ë” + ë””ì½”ë” + ì „ì²´ ì˜¤í† ì¸ì½”ë” ì •ì˜
    # ===================================================
    def build_model(self):
        # -----------------------------
        # 1. ì¸ì½”ë” êµ¬ì„± (ì…ë ¥ â†’ ì ì¬ê³µê°„ ë²¡í„°)
        # -----------------------------
        encoder_input = tf.keras.layers.Input(shape=(self.input_output_dim,), dtype=tf.float32)

        # íˆë“  ë ˆì´ì–´ ìˆœì°¨ì ìœ¼ë¡œ ì—°ê²°
        encoder_h_layer = encoder_input
        for dim in self.encoder_hidden_layers:
            encoder_h_layer = tf.keras.layers.Dense(
                units=dim,              # ê° ë ˆì´ì–´ì˜ ë…¸ë“œ ìˆ˜
                activation=self.relu,   # í™œì„±í™” í•¨ìˆ˜: ReLU (ë¹„ì„ í˜•ì„± ë¶€ì—¬)
                use_bias=True
            )(encoder_h_layer)

        # ì ì¬ë²¡í„°(code) ì¶œë ¥ì¸µ: ì••ì¶• í‘œí˜„
        code = tf.keras.layers.Dense(
            units=self.code_dim,
            activation=self.tanh,       # tanh: -1 ~ 1 ë²”ìœ„ë¡œ ì¶œë ¥ ì œí•œ
            use_bias=True
        )(encoder_h_layer)

        # ì¸ì½”ë” ëª¨ë¸ ìƒì„±
        self.encoder = tf.keras.models.Model(inputs=encoder_input, outputs=code)

        # -----------------------------
        # 2. ë””ì½”ë” êµ¬ì„± (ì ì¬ë²¡í„° â†’ ë³µì›ëœ ì¶œë ¥)
        # -----------------------------
        decoder_input = tf.keras.layers.Input(shape=(self.code_dim,), dtype=tf.float32)

        # íˆë“  ë ˆì´ì–´ êµ¬ì„±
        decoder_h_layer = decoder_input
        for dim in self.decoder_hidden_layers:
            decoder_h_layer = tf.keras.layers.Dense(
                units=dim,
                activation=self.relu,
                use_bias=True
            )(decoder_h_layer)

        # ì¶œë ¥ì¸µ: ì›ë˜ ì…ë ¥ê³¼ ê°™ì€ ì°¨ì›ìœ¼ë¡œ ë³µì› (ë¹„í™œì„±í™”í•¨ìˆ˜ ì—†ìŒ â†’ ì—°ì†ê°’ ê·¸ëŒ€ë¡œ ì¶œë ¥)
        decoder_output = tf.keras.layers.Dense(
            units=self.input_output_dim,
            activation=None,           # íšŒê·€ ë¬¸ì œì´ë¯€ë¡œ ì¶œë ¥ê°’ì— í™œì„±í™” í•¨ìˆ˜ ì—†ìŒ
            use_bias=True
        )(decoder_h_layer)

        # ë””ì½”ë” ëª¨ë¸ ìƒì„±
        self.decoder = tf.keras.models.Model(inputs=decoder_input, outputs=decoder_output)

        # -----------------------------
        # 3. ì „ì²´ AutoEncoder ì—°ê²° (Encoder â†’ Decoder)
        # -----------------------------
        vae_output = self.decoder(code)  # ì¸ì½”ë”ì˜ ì¶œë ¥(code)ì„ ë””ì½”ë”ì— ë°”ë¡œ ë„£ìŒ
        self.en_decoder = tf.keras.models.Model(inputs=encoder_input, outputs=vae_output)

        # -----------------------------
        # 4. í•™ìŠµ ì„¤ì • (ì»´íŒŒì¼ ë‹¨ê³„)
        # -----------------------------
        optimizer_alg = tf.keras.optimizers.Adam(learning_rate=0.001)  # í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì„¤ì • (Adam)

        # ì†ì‹¤ í•¨ìˆ˜: í‰ê·  ì œê³± ì˜¤ì°¨ (ì…ë ¥ê³¼ ì¶œë ¥ ê°„ì˜ ê±°ë¦¬ ê³„ì‚°)
        mse = tf.keras.losses.mse

        # ì „ì²´ ëª¨ë¸ ì»´íŒŒì¼ (í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ)
        self.en_decoder.compile(optimizer=optimizer_alg, loss=mse)

    # ===================================================
    # ğŸ§ª ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
    # - ì…ë ¥ê³¼ ì¶œë ¥ì´ ë™ì¼í•œ ë°ì´í„°ë¥¼ ì´ìš©í•´ AutoEncoder í•™ìŠµ
    # ===================================================
    def fit(self, x, y, batch_size, epochs):
        # x: ì…ë ¥ ì´ë¯¸ì§€ (ë²¡í„°í™”ëœ MNIST ë“±)
        # y: ì¶œë ¥ ì´ë¯¸ì§€ (ì˜¤í† ì¸ì½”ë” íŠ¹ì„±ìƒ ì…ë ¥ê³¼ ë™ì¼í•¨)
        self.en_decoder.fit(x=x, y=y, batch_size=batch_size, epochs=epochs)

    # ===================================================
    # ğŸ’¾ ê°€ì¤‘ì¹˜ ì €ì¥ í•¨ìˆ˜
    # - í•™ìŠµëœ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•¨
    # ===================================================
    def save_weights(self, save_path):
        self.en_decoder.save_weights(save_path)

    # ===================================================
    # ğŸ“‚ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
    # - ì €ì¥ëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ì—¬ ê¸°ì¡´ ëª¨ë¸ì— ì ìš©
    # ===================================================
    def load_weights(self, load_path):
        self.en_decoder.load_weights(load_path)
